## üìö Bu·ªïi 12 ‚Äì C√°c m√¥ h√¨nh Generative kh√°c: VAE, Diffusion Models v√† ·ª©ng d·ª•ng trong ngh·ªá thu·∫≠t t·∫°o h√¨nh

### üéØ M·ª•c ti√™u:

*   Hi·ªÉu v√† n·∫Øm b·∫Øt c√°c m√¥ h√¨nh Generative kh√°c ngo√†i GAN, bao g·ªìm **Variational Autoencoders (VAE)** v√† **Diffusion Models**.
*   N·∫Øm b·∫Øt c√°c ·ª©ng d·ª•ng c·ªßa c√°c m√¥ h√¨nh n√†y trong ngh·ªá thu·∫≠t t·∫°o h√¨nh v√† c√°c lƒ©nh v·ª±c kh√°c.
*   L√†m quen v·ªõi c√°ch s·ª≠ d·ª•ng c√°c m√¥ h√¨nh h·ªçc s√¢u trong vi·ªác t·∫°o ra h√¨nh ·∫£nh v√† video t·ª´ d·ªØ li·ªáu c√≥ s·∫µn.

---

### üîç N·ªôi dung ch√≠nh:

#### 1. **Gi·ªõi thi·ªáu v·ªÅ Variational Autoencoders (VAE):**

*   **Autoencoders**: M√¥ h√¨nh h·ªçc kh√¥ng gi√°m s√°t h·ªçc c√°ch n√©n d·ªØ li·ªáu v√†o kh√¥ng gian ·∫©n v√† t√°i t·∫°o l·∫°i d·ªØ li·ªáu t·ª´ kh√¥ng gian n√†y.
*   **Variational Autoencoders (VAE)** l√† phi√™n b·∫£n c·∫£i ti·∫øn c·ªßa Autoencoder, s·ª≠ d·ª•ng l√Ω thuy·∫øt th·ªëng k√™ ƒë·ªÉ ƒëi·ªÅu khi·ªÉn kh√¥ng gian ·∫©n sao cho m√¥ h√¨nh c√≥ th·ªÉ sinh d·ªØ li·ªáu m·ªõi (generative model).
    *   VAE thay v√¨ ch·ªâ ƒë∆°n gi·∫£n n√©n d·ªØ li·ªáu v√†o m·ªôt kh√¥ng gian ·∫©n c·ªë ƒë·ªãnh, n√≥ h·ªçc ph√¢n ph·ªëi x√°c su·∫•t c·ªßa kh√¥ng gian ·∫©n v√† m·∫´u t·ª´ ph√¢n ph·ªëi ƒë√≥ ƒë·ªÉ t·∫°o ra d·ªØ li·ªáu m·ªõi.
*   **C·∫•u tr√∫c VAE**:
    *   **Encoder**: M·∫°ng n∆°-ron chuy·ªÉn ƒë·∫ßu v√†o th√†nh ph√¢n ph·ªëi x√°c su·∫•t trong kh√¥ng gian ·∫©n (mean, variance).
    *   **Decoder**: M·∫°ng n∆°-ron chuy·ªÉn t·ª´ kh√¥ng gian ·∫©n tr·ªü l·∫°i th√†nh d·ªØ li·ªáu.
*   **Loss function c·ªßa VAE**:
    *   **Reconstruction loss**: ƒêo l∆∞·ªùng ƒë·ªô ch√≠nh x√°c c·ªßa vi·ªác t√°i t·∫°o l·∫°i d·ªØ li·ªáu g·ªëc.
    *   **KL divergence**: ƒêo l∆∞·ªùng s·ª± kh√°c bi·ªát gi·ªØa ph√¢n ph·ªëi ·∫©n h·ªçc ƒë∆∞·ª£c v√† ph√¢n ph·ªëi chu·∫©n (th∆∞·ªùng l√† Gaussian).

**Gi·∫£i th√≠ch:**

*   **Autoencoders:** M√¥ h√¨nh h·ªçc kh√¥ng gi√°m s√°t ƒë·ªÉ n√©n v√† t√°i t·∫°o d·ªØ li·ªáu.
*   **Variational Autoencoders (VAE):** M√¥ h√¨nh Generative d·ª±a tr√™n Autoencoders.
*   **C·∫•u tr√∫c VAE:** Encoder v√† Decoder.
*   **Loss function c·ªßa VAE:** Reconstruction loss v√† KL divergence.

#### 2. **·ª®ng d·ª•ng c·ªßa VAE:**

*   **Image Generation**: T·∫°o ra h√¨nh ·∫£nh t·ª´ kh√¥ng gian ·∫©n.
*   **Data Augmentation**: T·∫°o ra c√°c d·ªØ li·ªáu m·ªõi t·ª´ ph√¢n ph·ªëi x√°c su·∫•t.
*   **Latent Space Manipulation**: T·∫°o ra c√°c thay ƒë·ªïi trong kh√¥ng gian ·∫©n v√† sinh d·ªØ li·ªáu m·ªõi theo c√°c bi·∫øn ƒë·ªïi n√†y.

**Gi·∫£i th√≠ch:**

*   **Image Generation:** T·∫°o h√¨nh ·∫£nh m·ªõi.
*   **Data Augmentation:** TƒÉng c∆∞·ªùng d·ªØ li·ªáu hu·∫•n luy·ªán.
*   **Latent Space Manipulation:** Thay ƒë·ªïi kh√¥ng gian ·∫©n ƒë·ªÉ t·∫°o ra c√°c bi·∫øn th·ªÉ d·ªØ li·ªáu.

#### 3. **Gi·ªõi thi·ªáu v·ªÅ Diffusion Models:**

*   **Diffusion Models** l√† m·ªôt l·ªõp m√¥ h√¨nh generative r·∫•t m·∫°nh m·∫Ω, ho·∫°t ƒë·ªông b·∫±ng c√°ch "ph√° v·ª°" d·ªØ li·ªáu th√†nh nhi·ªÖu v√† sau ƒë√≥ "h·ªìi ph·ª•c" n√≥ t·ª´ nhi·ªÖu ƒë√≥.
*   Qu√° tr√¨nh diffusion m√¥ ph·ªèng qu√° tr√¨nh nhi·ªÖu h√≥a d·∫ßn d·∫ßn, sau ƒë√≥ l√† qu√° tr√¨nh h·ªìi ph·ª•c (denoising).
*   **C√°c ·ª©ng d·ª•ng c·ªßa Diffusion Models**:
    *   **Text-to-Image generation**: T·∫°o ra h√¨nh ·∫£nh t·ª´ m√¥ t·∫£ vƒÉn b·∫£n (Text-to-image).
    *   **Image Super-Resolution**: T·∫°o h√¨nh ·∫£nh ƒë·ªô ph√¢n gi·∫£i cao t·ª´ h√¨nh ·∫£nh ƒë·ªô ph√¢n gi·∫£i th·∫•p.
    *   **Inpainting**: S·ª≠a ch·ªØa ph·∫ßn b·ªã thi·∫øu ho·∫∑c l·ªói trong h√¨nh ·∫£nh.
*   **∆Øu ƒëi·ªÉm c·ªßa Diffusion Models**:
    *   T·∫°o ra h√¨nh ·∫£nh ch·∫•t l∆∞·ª£ng cao h∆°n GAN trong nhi·ªÅu tr∆∞·ªùng h·ª£p.
    *   Kh√¥ng g·∫∑p v·∫•n ƒë·ªÅ mode collapse nh∆∞ trong GANs.
    *   Qu√° tr√¨nh h·ªçc m√¥ ph·ªèng v·ªõi s·ª± nhi·ªÖu h√≥a v√† ph·ª•c h·ªìi d·ªØ li·ªáu r·∫•t hi·ªáu qu·∫£ trong vi·ªác t·∫°o ra d·ªØ li·ªáu ch√¢n th·ª±c.

**Gi·∫£i th√≠ch:**

*   **Diffusion Models:** M√¥ h√¨nh Generative d·ª±a tr√™n qu√° tr√¨nh khu·∫øch t√°n.
*   **·ª®ng d·ª•ng:** C√°c ·ª©ng d·ª•ng ph·ªï bi·∫øn c·ªßa Diffusion Models.
*   **∆Øu ƒëi·ªÉm:** C√°c ∆∞u ƒëi·ªÉm so v·ªõi GAN.

#### 4. **S·ª≠ d·ª•ng VAE v√† Diffusion Models trong Ngh·ªá thu·∫≠t T·∫°o H√¨nh:**

*   **V·∫Ω tranh, t·∫°o h√¨nh ·∫£nh ngh·ªá thu·∫≠t**: C·∫£ VAE v√† Diffusion Models c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o ra c√°c h√¨nh ·∫£nh ngh·ªá thu·∫≠t, t·ª´ tranh v·∫Ω cho ƒë·∫øn h√¨nh ·∫£nh hi·ªán th·ª±c.
*   **C√°c ·ª©ng d·ª•ng kh√°c**: Ngo√†i vi·ªác t·∫°o h√¨nh ·∫£nh, c√°c m√¥ h√¨nh n√†y c√≤n c√≥ th·ªÉ ƒë∆∞·ª£c √°p d·ª•ng trong vi·ªác t·∫°o video, chuy·ªÉn ƒë·ªïi phong c√°ch h√¨nh ·∫£nh, t·∫°o ·∫£nh 3D t·ª´ ·∫£nh 2D.

**Gi·∫£i th√≠ch:**

*   **V·∫Ω tranh, t·∫°o h√¨nh ·∫£nh ngh·ªá thu·∫≠t:** ·ª®ng d·ª•ng trong vi·ªác t·∫°o ra c√°c t√°c ph·∫©m ngh·ªá thu·∫≠t.
*   **C√°c ·ª©ng d·ª•ng kh√°c:** C√°c ·ª©ng d·ª•ng kh√°c c·ªßa VAE v√† Diffusion Models.

---

### üß™ B√†i lab Bu·ªïi 12:

#### 1. **X√¢y d·ª±ng v√† hu·∫•n luy·ªán VAE ƒë·ªÉ t·∫°o h√¨nh ·∫£nh:**

```python
import torch
from torch import nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torch.autograd import Variable

# C·∫•u tr√∫c VAE
class VAE(nn.Module):
    def __init__(self):
        super(VAE, self).__init__()
        # Encoder
        self.fc1 = nn.Linear(784, 400)
        self.fc21 = nn.Linear(400, 20)  # Mean
        self.fc22 = nn.Linear(400, 20)  # Log variance
        # Decoder
        self.fc3 = nn.Linear(20, 400)
        self.fc4 = nn.Linear(400, 784)

    def encode(self, x):
        h1 = torch.relu(self.fc1(x.view(-1, 784)))
        return self.fc21(h1), self.fc22(h1)

    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5*logvar)
        eps = torch.randn_like(std)
        return mu + eps*std

    def decode(self, z):
        h3 = torch.relu(self.fc3(z))
        return torch.sigmoid(self.fc4(h3))

    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar

# Loss function VAE
def vae_loss(recon_x, x, mu, logvar):
    BCE = nn.functional.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')
    # KL divergence between Gaussian prior and posterior
    # The prior is a standard normal, so mean=0 and variance=1
    # The posterior is defined by mu and logvar (output of the encoder)
    # This gives the KL divergence between two Gaussian distributions
    # which is calculated as 0.5 * (log(sigma^2) - log(sigma_0^2) - 1 + (mu - mu_0)^2 / sigma_0^2)
    # Here, sigma_0^2 = 1 and mu_0 = 0
    # This simplifies to the equation:
    # 0.5 * (mu^2 + exp(logvar) - logvar - 1)
    # where mu and logvar are from the encoder
    # and recon_x is the reconstructed image.
    MSE = 0.5 * torch.sum(mu.pow(2) + torch.exp(logvar) - logvar - 1)
    return BCE + MSE

# Hu·∫•n luy·ªán VAE
model = VAE()
optimizer = optim.Adam(model.parameters(), lr=1e-3)

# Dataloader cho b·ªô d·ªØ li·ªáu MNIST
train_loader = DataLoader(datasets.MNIST('.', train=True, download=True, transform=transforms.ToTensor()), batch_size=128, shuffle=True)

# Hu·∫•n luy·ªán VAE
model.train()
for epoch in range(10):
    train_loss = 0
    for data, _ in train_loader:
        data = Variable(data)
        optimizer.zero_grad()
        recon_batch, mu, logvar = model(data)
        loss = vae_loss(recon_batch, data, mu, logvar)
        loss.backward()
        train_loss += loss.item()
        optimizer.step()
    print('Epoch {}, Training loss {}'.format(epoch, train_loss / len(train_loader.dataset)))
```

**H∆∞·ªõng d·∫´n:**

*   X√¢y d·ª±ng l·ªõp VAE v·ªõi Encoder v√† Decoder.
*   ƒê·ªãnh nghƒ©a loss function cho VAE.
*   Hu·∫•n luy·ªán VAE tr√™n b·ªô d·ªØ li·ªáu MNIST.

#### 2. **S·ª≠ d·ª•ng Diffusion Models ƒë·ªÉ t·∫°o h√¨nh ·∫£nh t·ª´ vƒÉn b·∫£n**:

```python
from diffusers import StableDiffusionPipeline
import torch

# T·∫£i m√¥ h√¨nh Diffusion
pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4-original", torch_dtype=torch.float16)
pipe.to("cuda")

# S·ª≠ d·ª•ng m√¥ h√¨nh t·∫°o h√¨nh ·∫£nh t·ª´ vƒÉn b·∫£n
prompt = "A beautiful landscape with mountains and a river"
image = pipe(prompt).images[0]
image.show()
```

**H∆∞·ªõng d·∫´n:**

*   C√†i ƒë·∫∑t th∆∞ vi·ªán `diffusers`.
*   T·∫£i m√¥ h√¨nh Stable Diffusion.
*   S·ª≠ d·ª•ng m√¥ h√¨nh ƒë·ªÉ t·∫°o h√¨nh ·∫£nh t·ª´ vƒÉn b·∫£n.

---

### üìù B√†i t·∫≠p v·ªÅ nh√† Bu·ªïi 12:

1.  **T·∫°o m√¥ h√¨nh VAE c·ªßa b·∫°n**:

    *   T·∫°o m·ªôt m√¥ h√¨nh VAE ƒë·ªÉ t·∫°o ra h√¨nh ·∫£nh t·ª´ b·ªô d·ªØ li·ªáu MNIST.
    *   So s√°nh ch·∫•t l∆∞·ª£ng h√¨nh ·∫£nh t√°i t·∫°o gi·ªØa VAE v√† Autoencoder ƒë∆°n gi·∫£n.
2.  **S·ª≠ d·ª•ng Diffusion Models ƒë·ªÉ t·∫°o h√¨nh ·∫£nh**:

    *   S·ª≠ d·ª•ng m√¥ h√¨nh Diffusion ƒë·ªÉ t·∫°o h√¨nh ·∫£nh t·ª´ c√°c m√¥ t·∫£ vƒÉn b·∫£n c·ªßa b·∫°n.
    *   T·∫°o ra m·ªôt s·ªë h√¨nh ·∫£nh s√°ng t·∫°o t·ª´ m√¥ t·∫£ vƒÉn b·∫£n kh√°c nhau.
3.  **Kh√°m ph√° ·ª©ng d·ª•ng ngh·ªá thu·∫≠t c·ªßa Generative Models**:

    *   T√¨m hi·ªÉu th√™m v·ªÅ c√°ch c√°c m√¥ h√¨nh Generative nh∆∞ VAE v√† Diffusion ƒë∆∞·ª£c s·ª≠ d·ª•ng trong ngh·ªá thu·∫≠t s·ªë v√† t·∫°o h√¨nh ·∫£nh, video t·ª´ d·ªØ li·ªáu.
